import ast
import json
import os
from typing import Any, Dict, List, Optional, Tuple, Callable

from dotenv import load_dotenv
from ollama import chat

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ¯ä¸ªæµ‹è¯•çš„æœ€å¤§è¿è¡Œæ¬¡æ•°
NUM_RUNS_TIMES = 3


# ==========================
# å·¥å…·å®ç°éƒ¨åˆ† (æ‰§è¡Œå™¨)
# ==========================
def _annotation_to_str(annotation: Optional[ast.AST]) -> str:
    """å°† AST ç±»å‹æ³¨è§£è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚"""
    if annotation is None:
        return "None"
    try:
        return ast.unparse(annotation)  # type: ignore[attr-defined]
    except Exception:
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿›è¡Œç®€å•çš„å›é€€å¤„ç†
        if isinstance(annotation, ast.Name):
            return annotation.id
        return type(annotation).__name__


def _list_function_return_types(file_path: str) -> List[Tuple[str, str]]:
    """è§£æ Python æ–‡ä»¶å¹¶åˆ—å‡ºæ‰€æœ‰é¡¶çº§å‡½æ•°çš„å‡½æ•°ååŠå…¶è¿”å›ç±»å‹ã€‚"""
    with open(file_path, "r", encoding="utf-8") as f:
        source = f.read()
    tree = ast.parse(source)
    results: List[Tuple[str, str]] = []
    for node in tree.body:
        if isinstance(node, ast.FunctionDef):
            return_str = _annotation_to_str(node.returns)
            results.append((node.name, return_str))
    # æ’åºä»¥ä¿è¯è¾“å‡ºç»“æœç¨³å®š
    results.sort(key=lambda x: x[0])
    return results


def output_every_func_return_type(file_path: str = None) -> str:
    """å·¥å…·ï¼šè¿”å›æ¯ä¸ªé¡¶çº§å‡½æ•°çš„ 'å‡½æ•°å: è¿”å›ç±»å‹' åˆ—è¡¨ï¼ˆæ¢è¡Œç¬¦åˆ†éš”ï¼‰ã€‚"""
    path = file_path or __file__
    if not os.path.isabs(path):
        # å¦‚æœä¸æ˜¯ç»å¯¹è·¯å¾„ï¼Œå°è¯•ç›¸å¯¹äºå½“å‰è„šæœ¬æŸ¥æ‰¾æ–‡ä»¶
        candidate = os.path.join(os.path.dirname(__file__), path)
        if os.path.exists(candidate):
            path = candidate
    pairs = _list_function_return_types(path)
    return "\n".join(f"{name}: {ret}" for name, ret in pairs)


# ç¤ºä¾‹å‡½æ•°ï¼Œä»¥ä¾¿è„šæœ¬åˆ†ææ—¶æœ‰å†…å®¹å¯è¯»
def add(a: int, b: int) -> int:
    return a + b


def greet(name: str) -> str:
    return f"Hello, {name}!"


# å·¥å…·æ³¨å†Œè¡¨ï¼Œç”¨äºæ ¹æ®åç§°åŠ¨æ€æ‰§è¡Œå·¥å…·
TOOL_REGISTRY: Dict[str, Callable[..., str]] = {
    "output_every_func_return_type": output_every_func_return_type,
}

# ==========================
# æç¤ºè¯è„šæ‰‹æ¶
# ==========================

# TODO: Fill this in!
YOUR_SYSTEM_PROMPT = ""


def resolve_path(p: str) -> str:
    """è§£ææ–‡ä»¶è·¯å¾„ã€‚"""
    if os.path.isabs(p):
        return p
    here = os.path.dirname(__file__)
    c1 = os.path.join(here, p)
    if os.path.exists(c1):
        return c1
    return p


def extract_tool_call(text: str) -> Dict[str, Any]:
    """ä»æ¨¡å‹è¾“å‡ºä¸­è§£æå•ä¸ª JSON å¯¹è±¡ã€‚"""
    text = text.strip()
    # æŸäº›æ¨¡å‹ä¼šå°† JSON åŒ…è£¹åœ¨ä»£ç å—ä¸­ï¼Œå°è¯•å°†å…¶å»é™¤
    if text.startswith("```") and text.endswith("```"):
        text = text.strip("`")
        if text.lower().startswith("json\n"):
            text = text[5:]
    try:
        obj = json.loads(text)
        return obj
    except json.JSONDecodeError:
        raise ValueError("æ¨¡å‹æœªè¿”å›æœ‰æ•ˆçš„ JSON å·¥å…·è°ƒç”¨ã€‚å®é™…è¿”å›å†…å®¹ä¸ºï¼š\n" + text)


def run_model_for_tool_call(system_prompt: str) -> Dict[str, Any]:
    """å‘æ¨¡å‹å‘é€è¯·æ±‚ä»¥ç”Ÿæˆå·¥å…·è°ƒç”¨ã€‚"""
    response = chat(
        model="llama3.1:8b",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": "ç°åœ¨è¯·è°ƒç”¨å·¥å…·ã€‚"},
        ],
        options={"temperature": 0.3},
    )
    content = response.message.content
    return extract_tool_call(content)


def execute_tool_call(call: Dict[str, Any]) -> str:
    """æ ¹æ® JSON å®šä¹‰æ‰§è¡Œç›¸åº”çš„å·¥å…·ã€‚"""
    name = call.get("tool")
    if not isinstance(name, str):
        raise ValueError("å·¥å…·è°ƒç”¨ JSON ç¼ºå°‘ 'tool' å­—ç¬¦ä¸²å­—æ®µ")
    func = TOOL_REGISTRY.get(name)
    if func is None:
        raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")
    args = call.get("args", {})
    if not isinstance(args, dict):
        raise ValueError("å·¥å…·è°ƒç”¨ JSON çš„ 'args' å¿…é¡»æ˜¯ä¸€ä¸ªå¯¹è±¡")

    # å¦‚æœæœ‰ file_path å‚æ•°ä¸”ä¸ä¸ºç©ºï¼Œå°è¯•è§£æè·¯å¾„
    if "file_path" in args and isinstance(args["file_path"], str):
        args["file_path"] = resolve_path(args["file_path"]) if str(args["file_path"]) != "" else __file__
    elif "file_path" not in args:
        # ä¸ºæœŸæœ› file_path çš„å·¥å…·æä¾›é»˜è®¤å€¼
        args["file_path"] = __file__

    return func(**args)


def compute_expected_output() -> str:
    """æ ¹æ®å®é™…æ–‡ä»¶å†…å®¹è®¡ç®—é¢„æœŸè¾“å‡ºï¼ˆåŸºå‡†å€¼ï¼‰ã€‚"""
    return output_every_func_return_type(__file__)


def test_your_prompt(system_prompt: str) -> bool:
    """
    è¿è¡Œæµ‹è¯•ï¼šè¦æ±‚æ¨¡å‹ç”Ÿæˆæœ‰æ•ˆçš„å·¥å…·è°ƒç”¨ï¼Œå¹¶å°†å·¥å…·æ‰§è¡Œç»“æœä¸é¢„æœŸç»“æœè¿›è¡Œæ¯”å¯¹ã€‚
    """
    expected = compute_expected_output()
    for idx in range(NUM_RUNS_TIMES):
        print(f"æ­£åœ¨æ‰§è¡Œæµ‹è¯• {idx + 1} / {NUM_RUNS_TIMES}")
        try:
            call = run_model_for_tool_call(system_prompt)
        except Exception as exc:
            print(f"âŒ è§£æå·¥å…·è°ƒç”¨å¤±è´¥: {exc}")
            continue
        
        print(f"æ¨¡å‹ç”Ÿæˆçš„å·¥å…·è°ƒç”¨: {call}")
        try:
            actual = execute_tool_call(call)
        except Exception as exc:
            print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {exc}")
            continue
            
        if actual.strip() == expected.strip():
            print(f"ğŸ› ï¸ ç”Ÿæˆçš„è¾“å‡ºç»“æœ:\n{actual}")
            print("âœ¨ æµ‹è¯•é€šè¿‡ (SUCCESS)")
            return True
        else:
            print("âŒ é¢„æœŸè¾“å‡º:")
            print(expected)
            print("âŒ å®é™…è¾“å‡º:")
            print(actual)
            print("-" * 20)
    return False


if __name__ == "__main__":
    test_your_prompt(YOUR_SYSTEM_PROMPT)
